🚢 타이타닉 생존 예측: 로지스틱 회귀 모델 심층 분석1. 프로젝트 개요이 프로젝트는 고전적인 데이터셋인 타이타닉 생존 예측을 주제로 하여, 머신러닝의 가장 기본이 되는 로지스틱 회귀(Logistic Regression) 모델을 직접 구축하고 평가하는 과정을 심층적으로 다루었습니다.주요 목표:NumPy 기반 구현: 로지스틱 회귀 모델의 수학적 원리와 **최적화 과정(경사 하강법)**을 코드로 직접 구현하여 알고리즘에 대한 근본적인 이해를 다집니다.Scikit-learn을 활용한 표준화: 실무 표준 라이브러리인 Scikit-learn을 사용하여 모델을 구현하고, 다양한 평가 지표를 활용하여 모델의 성능을 체계적으로 분석합니다.이 포트폴리오는 단순한 모델 사용을 넘어, 알고리즘의 내부 작동 원리를 완벽히 이해했음을 보여주는 데 중점을 둡니다.2. 사용 기술 및 라이브러리유형라이브러리용도핵심Python전체 프로젝트 개발 언어수학/연산NumPy로지스틱 회귀 모델의 핵심 계산 및 행렬 연산 (NumPy 구현 시 필수)데이터 처리Pandas데이터 로드, 전처리 및 조작모델링Scikit-learn표준 로지스틱 회귀 모델 구현 및 성능 평가 지표 계산시각화Matplotlib, Seaborn데이터 탐색 및 손실 함수(Loss) 시각화3. 데이터 전처리 과정 요약모델 학습에 적합하도록 타이타닉 데이터를 정제하는 과정은 다음과 같습니다.단계처리 대상 컬럼처리 내용불필요 컬럼 제거adult_male, deck, embark_town, alive, alone, who, class 등예측과 직접적인 관련이 적거나 중복되는 정보를 가진 컬럼을 제거했습니다.결측치(NaN) 처리Age나이(Age)의 결측치는 데이터의 **중앙값(Median)**으로 대체하여 데이터 손실을 최소화했습니다.결측치(NaN) 처리Embarked승선지(Embarked)의 결측치는 가장 빈도가 높은 값인 **최빈값(Mode)**으로 대체했습니다.결측치 컬럼 제거Cabin결측치가 과도하게 많아 예측 성능에 방해가 될 수 있다고 판단하여 컬럼 자체를 제거했습니다.범주형 변수 인코딩Sex, Embarked문자열 형태의 범주형 데이터를 모델이 학습할 수 있도록 숫자 형태로 변환했습니다 (예: One-Hot Encoding 또는 Label Encoding).타겟 변수 설정Survived이진 분류 문제의 타겟(y) 변수로 설정했습니다.4. 모델 원리: NumPy 구현을 통한 이해로지스틱 회귀 모델의 핵심 원리를 이해하기 위해 NumPy만을 사용하여 모델을 구현했으며, 그 핵심 구성 요소는 다음과 같습니다.4.1. 가설 함수 (Hypothesis Function) - 시그모이드선형 모델의 결과($Z = WX + b$)를 0과 1 사이의 확률값으로 변환하는 함수입니다.$$\sigma(Z) = \frac{1}{1 + e^{-Z}}$$4.2. 손실 함수 (Loss Function) - 이진 교차 엔트로피예측된 확률값과 실제 정답 레이블 간의 오차를 측정하는 함수입니다. 이 오차를 최소화하는 방향으로 학습이 진행됩니다.$$\text{Log Loss (Binary Cross-Entropy)}: J(W) = -\frac{1}{m} \sum_{i=1}^{m} [y^{(i)} \log(h_W(x^{(i)})) + (1-y^{(i)}) \log(1-h_W(x^{(i)}))]$$4.3. 최적화 - 경사 하강법 (Gradient Descent)손실 함수의 최솟값을 찾기 위해 가중치($W$)와 편향($b$)을 **손실 함수의 기울기(미분값)**를 따라 조금씩 업데이트하는 반복적인 최적화 기법입니다.$$\text{Update Rule}: W := W - \alpha \frac{\partial J(W)}{\partial W}$$[NumPy 구현을 통해 손실이 감소하는 그래프 이미지]5. 최종 결과 및 해석 (Scikit-learn)Scikit-learn의 LogisticRegression을 사용하여 최종 모델을 훈련하고, 테스트 세트를 기반으로 성능을 평가했습니다.5.1. 평가 지표지표값 (예시)의미정확도(Accuracy)0.8201전체 예측 중 약 82.01%를 올바르게 예측했습니다.정밀도(Precision)0.8261모델이 '생존'이라고 예측한 승객 중 실제 생존한 비율입니다.재현율(Recall)0.7215실제 생존한 승객 중 모델이 '생존'이라고 올바르게 찾아낸 비율입니다.F1-Score0.7780정밀도와 재현율의 균형을 나타내는 지표입니다.5.2. 결과 해석: 재현율(Recall)의 중요성 강조타이타닉 생존 예측과 같이 생명과 관련된 문제에서는 오류의 종류를 구분하여 지표를 해석하는 것이 중요합니다.False Negative (FN): 실제 생존자를 사망자로 잘못 예측하는 경우. (가장 피해야 할 오류)False Positive (FP): 사망자를 생존자로 잘못 예측하는 경우.이 프로젝트의 목표가 '생존자를 최대한 놓치지 않고 구출하는 것'이라고 가정할 때, 실제 생존자(Positive)를 얼마나 잘 찾아내는지를 나타내는 재현율(Recall) 지표가 가장 중요한 평가지표가 됩니다. 모델의 재현율이 72.15%라는 것은, 실제 생존자의 약 72%를 성공적으로 예측했음을 의미합니다.6. 개선 방향 및 자기 고찰6.1. 내가 배운 것 (자기 고찰)근본 원리 체득: 단순한 API 호출이 아닌, NumPy로 직접 행렬 연산과 미분 기반의 경사 하강법을 구현해보면서 머신러닝 모델의 학습 과정이 **'손실 함수의 최솟값을 찾아가는 최적화 과정'**임을 명확히 이해하게 되었습니다.표준 도구의 필요성: NumPy 구현을 통해 원리를 이해한 후, Scikit-learn을 통해 데이터 파이프라인 구축과 체계적인 성능 평가의 중요성을 경험했습니다.6.2. 향후 개선 방향현재 학습 수준에서 모델의 성능을 개선하고 이해도를 높이기 위해 다음과 같은 추가 작업을 고려할 수 있습니다.특성 공학 (Feature Engineering): 현재 특성 외에 SibSp (형제/배우자)와 Parch (부모/자녀)를 합쳐 **FamilySize**와 같은 새로운 특성을 만들어 모델에 더 풍부한 정보를 제공할 수 있습니다.하이퍼파라미터 튜닝: Scikit-learn 로지스틱 회귀의 규제 강도(C) 값이나, NumPy 구현 시 사용한 학습률(Learning Rate)을 체계적으로 변경하며 최적의 모델을 탐색할 수 있습니다.다른 모델 탐색: 로지스틱 회귀가 선형 분류기이므로, **결정 트리(Decision Tree)**나 **랜덤 포레스트(Random Forest)**와 같은 비선형 모델을 적용하여 데이터 내의 복잡한 비선형 관계를 학습할 수 있는지 탐색해 볼 것입니다.
